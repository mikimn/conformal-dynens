{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cp import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Tbk_fJSGrUU"
   },
   "source": [
    "\n",
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ust_L_ffJPP-",
    "outputId": "4d396b90-d008-44ce-cc93-fbceb1eb0ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\r\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\r\n",
      "Cuda compilation tools, release 11.0, V11.0.221\r\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michael.me/miniconda3/envs/py37/bin/nvcc\r\n"
     ]
    }
   ],
   "source": [
    "!which nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqJT4jtyJoXq",
    "outputId": "9d720cb9-e831-4d71-c4a0-87c265b002c6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TQUleA36KERW"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('drive/MyDrive/Master/Reliability in ML/dynens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7qex5dfKl0d",
    "outputId": "6f4cac6d-2979-4bf6-a096-92a25a1cedc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp.py\t\t   images\t   output\trelated\t\t  venv\r\n",
      "data\t\t   jupyter-lab.sh  __pycache__\trequirements.txt\r\n",
      "experiments.ipynb  model\t   README.md\tscript\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b-n1rSrdPZgh"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MmVKSqumMZH5"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get --purge remove cuda nvidia* libnvidia-*\n",
    "# !sudo dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
    "# !sudo apt-get remove cuda-*\n",
    "# !sudo apt autoremove\n",
    "# !sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8Eg729NCGugz"
   },
   "outputs": [],
   "source": [
    "# !sudo dpkg -i cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n2GnOKucLWxA"
   },
   "outputs": [],
   "source": [
    "# !ls /var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fGANgRRoHCrE"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub\n",
    "# !sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xz8w72kxMGVx"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get -y install cuda-10-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6P-QzXScZws4",
    "outputId": "c662ef53-36f2-403a-b54e-d7aa964dc317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  1 16:19:24 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\r\n",
      "| 33%   34C    P0    28W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSzWG-i3OaUW"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZY_5Yq-OqiY"
   },
   "source": [
    "### Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "HpNkBvndZpz5",
    "outputId": "7ffe078d-66f7-4079-e95e-b1f5ba943db9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 16:19:24.646797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 16:19:26.687480: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 16:19:26.689100: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-01 16:19:28.130573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-01 16:19:28.130632: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-01 16:19:28.134401: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-01 16:19:28.134501: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-01 16:19:28.136334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-01 16:19:28.136823: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-01 16:19:28.140988: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-01 16:19:28.142039: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-01 16:19:28.171581: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-01 16:19:28.173799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-01 16:19:28.192682: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-01 16:19:33.344628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-01 16:19:33.344668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-01 16:19:33.344677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-01 16:19:33.348361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 9659 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1e:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x  \n",
    "import tensorflow as tf  \n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mNFR0ErWOstG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "methods to read polarity data \n",
    "and make it avaiable for fasttext classification\n",
    "Done by Tere\n",
    "Nov 7, 2019\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.preprocessing.sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from tensorflow.contrib import learn\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "text processing\n",
    "and split text/train\n",
    "\"\"\"\n",
    "def prepare_text(x,num_words,max_len):\n",
    "    \n",
    "    print (\"to tokenize\")\n",
    "    #split test and training\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    \n",
    "    print (\"unique tokens:\",len(tokenizer.word_index))\n",
    "    x = tokenizer.texts_to_sequences(x)\n",
    "    x = pad_sequences(x, maxlen=max_len,padding='post', truncating='pre')\n",
    "    \n",
    "    return x\n",
    "    \n",
    "def read_yahoo_files(file_train, file_test,file_val):\n",
    "    \n",
    "    names  = [\"class\", \"questionlabel\",\"questionContent\",\"answer\"]\n",
    "    \n",
    "    df_train   = pd.read_csv(file_train,names=names)\n",
    "    df_test    = pd.read_csv(file_test,names=names)\n",
    "    df_val     = pd.read_csv(file_val,names=names)\n",
    "    \n",
    "    train_len = len(df_train)\n",
    "    test_len  = len(df_test)\n",
    "    val_len   = len(df_val)\n",
    "    \n",
    "    print (\"train len =\",train_len)\n",
    "    print (\"test len  =\",test_len)\n",
    "    print (\"val len   =\",val_len)\n",
    "    \n",
    "    df = pd.concat([df_train,df_test,df_val])\n",
    "    \n",
    "    x_text = df[\"questionlabel\"].astype(str) +\" \"+df[\"questionContent\"].astype(str) +\" \"+df[\"answer\"].astype(str)\n",
    "    #x_text = df[\"answer\"].astype(str)\n",
    "    x = x_text.tolist() #np.array(x_text)#x_text.tolist(\n",
    "    df_y = df[\"class\"]\n",
    "    y = pd.get_dummies(df_y,columns=['class']).values \n",
    "    return x,y, train_len,test_len, val_len\n",
    "                     \n",
    "def load_data_yahoo_ans(src_path, max_words=20000,max_len=1000):\n",
    "    fileTrain = src_path + \"train.csv\"\n",
    "    fileTest  = src_path + \"test.csv\"\n",
    "    fileVal  = src_path + \"val.csv\"\n",
    "\n",
    "    print (\"to read\")\n",
    "    x,y,train_len,test_len,val_len = read_yahoo_files(fileTrain,fileTest,fileVal)\n",
    "    \n",
    "    print (\"to process\")\n",
    "    x = prepare_text(x,max_words,max_len)\n",
    "    \n",
    "    print (\"to split\") \n",
    "    x_train = x[0:train_len,:]\n",
    "    y_train = y[0:train_len,:]\n",
    "    \n",
    "    x_test  = x[train_len:(train_len+test_len),:]\n",
    "    y_test  = y[train_len:(train_len+test_len),:]\n",
    "\n",
    "    x_val  = x[(train_len+test_len):(train_len+test_len+val_len),:]\n",
    "    y_val  = y[(train_len+test_len):(train_len+test_len+val_len),:]\n",
    "\n",
    "    print (\"New train SHAPE\")\n",
    "    print (x_train.shape)\n",
    "    print (y_train.shape)\n",
    "    \n",
    "    print (\"New test SHAPE\")\n",
    "    print (x_test.shape)\n",
    "    print (y_test.shape)\n",
    "    \n",
    "    print (\"New train SHAPE\")\n",
    "    print (x_test.shape)\n",
    "    print (y_test.shape)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test),(x_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDhyLJ8YOoxy"
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8CwGanRGg49N"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "text classification using\n",
    "keras-fasttext \n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "# import data_reader_yahoo as data_reader_yahoo\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "###############################################\n",
    "# user params\n",
    "###############################################\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-s\", \"--seed\", help=\"random seed\")\n",
    "parser.add_argument(\"-sd\", \"--savedir\", help=\"saving directory\")\n",
    "parser.add_argument(\"-f\", \"--datafile\", help=\"data file\", required=True)\n",
    "parser.add_argument(\"-k\", \"--topk\", help=\"top k models to save\", default=10)\n",
    "parser.add_argument(\"-g\",\"--gpu\",default=0)\n",
    "\n",
    "class Bunch:\n",
    "  def __init__(self, **entries):\n",
    "    self.__dict__.update(entries)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = Bunch(\n",
    "    seed=10,\n",
    "    savedir='./output/yahoo_answers_csv_imbalance3/DS1/baseline/run_1',\n",
    "    datafile='./data/yahoo_answers_csv_imbalance3/DS1',\n",
    "    topK=10,\n",
    "    gpu=0\n",
    ")\n",
    "save_dir = args.savedir\n",
    "datafile = args.datafile\n",
    "seed     = int(args.seed)\n",
    "gpuId    = args.gpu\n",
    "top_k    = 1\n",
    "\n",
    "#add gpu target\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir ./output/yahoo_answers_csv_imbalance3/DS1/baseline/run_1\n",
      "Setting seed.\n"
     ]
    }
   ],
   "source": [
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "# add destination dir:\n",
    "print (\"output dir\",save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    print(\"adding saving directory\")\n",
    "    os.makedirs(save_dir)\n",
    "# Set random seed\n",
    "if seed is not None:\n",
    "    print('Setting seed.')\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "###############################################\n",
    "# MODEL params\n",
    "###############################################\n",
    "# Set parameters:\n",
    "# ngram_range = 2 will add bi-grams features - we don't use this feature\n",
    "ngram_range = 1\n",
    "max_features = 10000\n",
    "maxlen = 1014\n",
    "batch_size = 16\n",
    "embedding_dims = 50\n",
    "epochs = 1\n",
    "#params\n",
    "num_classes =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rliiw-2HMRnM",
    "outputId": "3abddaa8-9279-4fa7-fbfb-918c7f619d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "to read\n",
      "train len = 683200\n",
      "test len  = 2440\n",
      "val len   = 26840\n",
      "to process\n",
      "to tokenize\n",
      "unique tokens: 668410\n",
      "to split\n",
      "New train SHAPE\n",
      "(683200, 1014)\n",
      "(683200, 9)\n",
      "New test SHAPE\n",
      "(2440, 1014)\n",
      "(2440, 9)\n",
      "New train SHAPE\n",
      "(2440, 1014)\n",
      "(2440, 9)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "683200 train sequences\n",
      "2440 test sequences\n",
      "Average train sequence length: 1014\n",
      "Average test sequence length: 1014\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (683200, 1014)\n",
      "x_test shape: (2440, 1014)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snapshot_window_size = int(math.ceil(epochs/top_k))\n",
    "print('Loading data...')\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "(x_train, y_train), (x_test, y_test) ,(x_val,y_val)= load_data_yahoo_ans(datafile,\n",
    "                                                                             max_words=max_features,\n",
    "                                                                             max_len=maxlen)\n",
    "\n",
    "print (type(x_train))\n",
    "print (type(y_train))\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_test)), dtype=int)))\n",
    "\n",
    "###############################################\n",
    "# MODEL definitions\n",
    "###############################################\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "\n",
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in x_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    x_train = add_ngram(x_train, token_indice, ngram_range)\n",
    "    x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)), dtype=int)))\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THNb4podW2jR",
    "outputId": "c342d034-3b98-46a6-f22e-97d8adda1168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 16:25:06.321796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-01 16:25:06.325249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(devices)\n",
    "tf.config.set_visible_devices(devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PIPk7EIWwY7",
    "outputId": "be642282-ebdd-4cc0-b84b-f1da757f1121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHKSYvTPb5XK",
    "outputId": "3adcba28-8232-4730-8bdf-d689c058e11d"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras import backend as K\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto())\n",
    "# K.set_session(sess)\n",
    "# os.environ.get(\"CUDA_VISIBLE_DEVICES\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kye91JxtSdRA",
    "outputId": "c3c450a1-d96d-458e-bc83-ec9e86b0a535"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 16:28:44.663385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-01 16:28:44.664682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-01 16:28:44.664735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-01 16:28:44.664747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-01 16:28:44.664757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-01 16:28:44.666044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9659 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1e:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 683200 samples, validate on 26840 samples\n",
      "682944/683200 [============================>.] - ETA: 0s - loss: 1.2852 - accuracy: 0.6015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael.me/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "683200/683200 [==============================] - 122s 179us/sample - loss: 1.2852 - accuracy: 0.6016 - val_loss: 1.0451 - val_accuracy: 0.6891\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'), tf.compat.v1.Session(config=tf.compat.v1.ConfigProto()):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    model.add(Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=maxlen))\n",
    "\n",
    "    # we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "    # of all words in the document\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    #model.add(Dense(2, activation='sigmoid'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    #model.compile(loss='binary_crossentropy',\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    cp = IcpClassifier(model)\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    # PREDICTION AND OUPUT\n",
    "    ###############################################\n",
    "    ## add logs\n",
    "    # Training log writer\n",
    "    logfile   = '{}/callback_training_log.csv'.format(save_dir)\n",
    "    csvlog    =  CSVLogger(logfile, separator=',', append=False)\n",
    "    callbacks = [csvlog]\n",
    "\n",
    "    history = cp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=callbacks\n",
    "          )\n",
    "\n",
    "    # Save the weights\n",
    "    model.save_weights(save_dir+'model_weights.h5')\n",
    "\n",
    "    # Save the model architecture\n",
    "    with open(save_dir+'model_architecture.json', 'w') as f:\n",
    "        f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2851576614121643],\n",
       " 'accuracy': [0.6015808],\n",
       " 'val_loss': [1.045074704062921],\n",
       " 'val_accuracy': [0.68908346]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training log...\n",
      "Writing index file and predict files...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_maybe_load_initial_epoch_from_ckpt() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47453/2315033192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{},{}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Save predicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpredictfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/prediction_{:04d}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_epoch_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _maybe_load_initial_epoch_from_ckpt() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Save training log\n",
    "print('Saving training log...')\n",
    "train_error    = history.history['loss']\n",
    "valid_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Save index for combination\n",
    "c = [str(i) for i in range(num_classes)]\n",
    "header = ','.join(c) + '\\n'\n",
    "print('Writing index file and predict files...')\n",
    "indexfile = '{}/index.csv'.format(save_dir)\n",
    "f = open(indexfile, 'w')\n",
    "top_x = []\n",
    "\n",
    "\n",
    "#we have a single file for prediciton\n",
    "# to check later.\n",
    "x=0\n",
    "name = 'prediction_{:04d}.csv'.format(x+1)\n",
    "#use the last model to predict\n",
    "weight = valid_accuracy[epochs-1]\n",
    "f.write('{},{}\\n'.format(name, weight))\n",
    "predicts = model.predict(x_test)\n",
    "# Save predicts\n",
    "predictfile = '{}/prediction_{:04d}.csv'.format(save_dir, x+1)\n",
    "f1 = open(predictfile,'w')\n",
    "f1.write(header)\n",
    "np.savetxt(f1, predicts, delimiter=\",\")\n",
    "f1.close()\n",
    "\n",
    "    \n",
    "# Save targets\n",
    "print('Saving target file...')\n",
    "targetfile = '{}/target.csv'.format(save_dir)\n",
    "f2 = open(targetfile,'w')\n",
    "f2.write(header)\n",
    "np.savetxt(f2, y_test, delimiter=\",\")\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiments",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
